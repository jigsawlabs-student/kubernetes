{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have learned a little about deployments, it's time to take some time to further understand how deployments and Kubernetes in general can help us manage our application.  As we mentioned, Kubernetes helps us with deploying and managing our containers.  In this lesson, we'll see some of those benefits in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at our deployment file for creating a new API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: api-deployment\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      component: api\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        component: api\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: flask-api\n",
    "          image: jek2141/flask_api\n",
    "          ports:\n",
    "          - containerPort: 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key part to notice in our deployment above is that we just specified the number of replicas of our pods that we wanted.  We did not have to worry about which particular computer -- referred to as nodes -- these would be deployed to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl apply -f api-deployment.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./deployment-and-nodes.jpg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So in the diagram above, Kubernetes distributed the pods across to different nodes (or computers) -- and as developers, we were happy to let Kubernetes decide on where to place this pod. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we didn't even need to start the containers up on the pods ourselves.  We simply applied our yaml file and watched Kubernetes perform this for us.  Now creating these pods may seem like this is a minimal task that Kubernetes performs for us, but there is a good amount of work involved.  We can see this with the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl describe pods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kubectl-describe-pods.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that Kubernetes had to move through the steps of pulling our image, creating and then starting our container.  And also deployed the pods to nodes of it's choosing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the number of Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things become more interesting when we say want to scale back the number of containers.  To do so, we can just change the number of replicas in our deployment yaml file, apply the change, and then Kubernetes will determine which container to shut down and terminate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: api-deployment\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      component: api\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        component: api\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: flask-api\n",
    "          image: jek2141/flask_api\n",
    "          ports:\n",
    "          - containerPort: 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl apply -f api-deployment.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./terminating-container.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that the status now changed to terminating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again, Kubernetes does the job of determining which pod to terminate, finding the pod on whichever machine it exists, and then removing the pod.  After a minute or two, we'll see that the pod has disappeared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Before applying the update** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./deployment-and-nodes.jpg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. After applying the update**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./api-deployment-updated.jpg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So with Kubernetes we do not need to worry about which nodes our pods are deployed on because Kubernetes will find them and determine which ones to remove.  Without Kubernetes we would have to find the container on the correct node, and then remove it ourselves.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Healing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional benefit that we can see from our deployment is self-healing.  For example, let's say our deployment specified there should be two replicas of a pod.  If one of those replicas or the machine it's running on crashes, Kubernetes will see that only one is running when we want two.  So Kubernetes will get to work creating a new pod to replace it.   \n",
    "\n",
    "Let's try this out.  We'll have our deployment specify two replicas of our pod, and then apply the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./two-pods.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll delete one of the pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./delete-pods.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we did command Kubernetes to delete one of the pods.  But the deployment still specifies there should be two pods.  Kubernetes will notice that there is one fewer pod running then specified in the deployment and create a new pod to rectify this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice in the image below, that even though one of the pods is now terminating, another pod is up and running to create it's place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kube-delete-status.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few moments, the earlier pod has been fully deleted, and all we have left is our two pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kube-status-updated.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is pretty special.  Even if one of our machines crashes in the middle of the night, Kubernetes will notice that there is a pod missing, and create a new one on a different machine to replace it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollouts and Rollbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployments also keep track of the changes we made in our template.  For example, let's check the number of revisions that were applied in the deployment's history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./deployment-rollout-history.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have two revisions in the deployment --one and two.  From here, let's inspect what occurred in each deployment.  \n",
    "\n",
    "> `kubectl rollout history deployment --revision=1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./revision-1.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in revision 1 we just specified the image.  And in the revision 2, we added in the port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./revision-2.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if, we decide we want to go back to revision one, we can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./rollback-deployment.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So this would be quite useful, if we applied an update that then caused something to fail, we can simply rollback the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we walked through some of the benefits from using deployments, and Kubernetes in general.  As we saw, with deployments, we simply specify the numbers of replicas that we want in our deployment, and Kubernetes will work to achieve this.  For example, if we want to decrease the number of replicas, we change our deployment file and apply the changes.  Kubernetes will do the work of determining which pod to eliminate and find the pod on whichever computer it lives, and destroy the pod.  So this allows to ignore the hardware issues of determining which pod lives on which machine.  We see additional benefits when say a machine a pod is running on accidentally shutsdown -- Kunbernetes will notice there are not the same pods running as specified in the deployment and will create a new pod on a different computer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
